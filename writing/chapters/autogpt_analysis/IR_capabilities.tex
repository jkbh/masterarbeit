\documentclass[../../main.tex]{subfiles}
\begin{document}
The AutoGPT Agent has different abilities that can be utilized for information retrieval.
Notably, it is able to search the web and operate on the file system.

The web search is implemented by a two-step process.
First a search API like DuckDuckGo is called to get a list of relevant pages.
Then the page contents are scraped with a headless browser.
It is possible to read and write to text files.
Other document types are processed by basic text extraction tools to get the plain text.

For longer files such as scientific journals the extracted text is too long for the language model.
The AutoGPT agent has no ability to chunk the text into smaller chunk or store it in a database.
This is a limitation that needs to be addressed for information retrieval tasks over a research database repository.

Having a vector database would enable techniques such as retrieval augmented generation.
The agent would get a prompt which a question over the RDR and choose an action to start a semantic search over the vector database.
The result of the search are the chunks that are semantically closest to the question.
These chunks can then be included as context for the LLM prompt to generate an answer.

The default agent has a tendency towards searching the web for information. We want an agent that prioritizes information that is present in the research repository.
This needs to be addressed in the prompting techniques of the agent.
\end{document}