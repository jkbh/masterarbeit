\documentclass[../main.tex]{subfiles}

\begin{document}
\chapter{Introduction}
\label{ch:introduction}

For a long time, \gls{ir} has been a heavily researched topic in computer science.
Retrieving information from a large set of documents is an essential task in many domains.
For example,
a researcher might want to discover relevant parts of a new article for a given topic.
Ideally he can chat with a retrieval system in natural language
and receive correct information from the article.
In recent years, there has been a large increase in language modeling capabilities.
\Glspl{llm} have been applied to a variety of applications such as general chatbots,
writing helpers and coding assistants.
There are different approaches to leverage \gls{ir} for \glspl{llm} systems such as \gls{rag}.
A \Gls{rag} system retrieves documents from a database before using them as context
for an \gls{llm} answer generation.
This method enables on-demand inclusion of information into the answer generation.
Recently, efforts were increased in using \glspl{llm} as agent controllers.
In comparison to static systems, agent systems act autonomously and goal-directed.
They constantly perceive the environment through sensors and perform actions
through actuators.
\Gls{autogpt} is an open-source project that uses \gls{gpt4} to provide agent
actions.
While there are experiments with \gls{autogpt} for navigating the web,
using it for \gls{ir} has not been researched yet.

This thesis presents a \gls{llm} agent built with \gls{autogpt},
that uses \gls{rag} to answer user prompts.
The agent is benchmarked with a small set of \gls{qa} pairs from a humanities journal.
A qualitative evaluation of the \gls{ir} agent benchmark is given in the results.

\section{Contributions of this Thesis}

This thesis has three main contributions:
\begin{enumerate}
    \item An analysis of \gls{autogpt} in the context of \gls{ir}.
    \item A custom \gls{ir} agent that uses \gls{rag} for \gls{ir}.
    \item A small humanities journal \gls{qa} benchmark to test the \gls{ir} agent.
\end{enumerate}

In the analysis, I conclude that to research \gls{ir} applications for \gls{autogpt},
an adaption of the default abilities for \gls{rag} is needed.
Due to the complexity of the default agent,
I further reason that it is best to build a custom agent with the baseline Forge agent.

The custom \gls{ir} agent is built with the Forge agent baseline included in the
\gls{autogpt} project.
A custom agent logic is implemented to define the agent loop.
The agent has abilities to ingest a PDF into its memory, retrieve documents for it
and use them to answer a user query.
Rather than following a fixed pipeline, the agent choose these actions to
dynamically perform the \gls{rag} steps.

The benchmarking dataset contains eight \gls{qa} pairs from a humanities journal.
I used GPT-4 to generate candidate questions and then handpicked answers from
the journal articles.
The \gls{ir} is compared to GPT-3, GPT-4 and Perplexity AI
using cosine similarity between the ground truth and generated answers.
There is no service that clearly outperforms the other ones.
A qualitative evaluation of the agent explains the common failure points.
The main problems of the agent are irrelevant retrieval results,
inconsistent \gls{llm} response formats and choosing wrong abilities.

\section{Related Work}

With the rise of \glspl{llm}, they have been introduced into different domains.
\Gls{llm} agents are a promising way to fulfill user goals autonomously,
hinting in the direction of real computer intelligence.
Language models have also seen rising popularity in \gls{ir} applications.
Many popular search engines have introduced language models to present the retrieved data to the user.
In the following, notable work that is of interest for this work is listed.

\subsection{LLM Agents}

After \glspl{llm} like \gls{gpt3} and then \gls{gpt4} were made public,
researchers started testing different approaches to integrate them into agents.
In particular, the introduction of tools to extend the language model capabilities
Toolformer \cite{Schick2023} trains a language model to use different APIs in a self-supervised way.
For example, the model can use a calculator to externalize math problems,
a task category that \glspl{llm} struggle with.
HuggingGPT \cite{Shen2023} uses \gls{gpt} repeatedly in multiple rounds.
For each step, a Huggingface model can be selected by the model to answer the prompt.
In a virtual social setting, multiagent communication was demonstrated in \autocite{Park2023}.
Agents living together in a virtual village have different goals and communicate through natural language.

Building on top of these research experiments with tool usage and access to external knowledge,
multiple applications of language model agents have been presented.
\Gls{autogpt} \cite{SignificantGravitas2023} is an attempt to make \gls{llm} autonomous.
The \gls{autogpt} agent has a variety of abilities such as web search,
image generation, code execution and file operations.
It uses GPT-4 to generate an action proposal from a list of abilities.
An introduction to \gls{autogpt} is given in \autoref{ch:autogpt}.
I will use the included Forge agent to build a custom agent in this thesis.

Besides \gls{autogpt}, other \gls{llm} agent projects have been published.
BabyAGI is a minimal task-driven autonomous agent \cite{Nakajima2023}.
With OpenAI Assistants~\cite{zotero-195},
users can build custom assistants
that can use OpenAI models, tools and knowledge to answer user queries.

\subsection{LLM Information Retrieval}

Because of their strong natural language capabilities,
many developers work on tools that use these models for \gls{ir}

% TODO Perplexity is also an agent? Differentiate between IR and Agent for PPAI
Perplexity AI \cite{zotero-197} is an online service that leverages a language model
to provide a search that generates an answer from different sources on the internet.
The content of the answer is then linked to the found sources,
so the user can see and verify the result.

\section{Structure of this Thesis}

First, I will introduce the main backgrounds
that are relevant to this work in \autoref{ch:backgrounds}.
The steps of an \gls{ir} system are explained, as well
as different strategies to evaluate such systems.
Furthermore, I will give an overview of the concept of an \emph{agent} and its main components.
Additionally, the language modeling section covers the base
to understand the current \glspl{llm}.
I will go from the introduction of the transformer architecture to current chat models like ChatGPT.
Finally, the combination of language models and agents to \emph{\gls{llm} agents} is introduced.
Chapter~\ref{ch:autogpt} contains an introduction to \gls{autogpt} and its core elements,
as well as an analysis of its current \gls{ir} capabilities.
First, an overview of the \gls{autogpt} project and its components is given.
I will then explain the default agent in more detail,
looking at how the \gls{llm} agent ideas are implemented.
After gaining an understanding of the \gls{autogpt} project,
we will then look at its default capabilities for \gls{ir} tasks.
In \autoref{ch:agent},
a custom \gls{autogpt} agent that uses \gls{rag} for \gls{ir} is presented.
I will introduce the concept of \gls{rag} first, then give a detailed explanation
of the \gls{ir} agent.
In \autoref{ch:benchmarks}, will deal with how \gls{llm} agents can be benchmarking
and present a test dataset for the \gls{rag} agent from \autoref{ch:agent}.
The benchmark uses handcrafted question-and-answer pairs from a scientific humanities journal.

\end{document}