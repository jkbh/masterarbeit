\documentclass[../main.tex]{subfiles}

\begin{document}
\chapter{Introduction}
\label{ch:introduction}

\begin{figure}[t]
    \centering
    \begin{tikzpicture}[node distance=2cm]
        \node[block=emph red] (workspace) {Workspace};
        \node[above=of workspace] (user) {User};
        \node[ability, below=of workspace] (retrieve) {Retrieve};
        \node[ability, left=2.5cm of workspace] (ingest) {Ingest};
        \node[ability, right=2.5cm of workspace] (answer) {Answer};
        \node (DB) at (ingest |- retrieve) {DB};
        \node[below=of answer] (LLM) {LLM};

        \draw[->] (user) -- node[left] {place PDF} (workspace);
        \draw[->] (workspace) -- node[above] {read PDF} (ingest);
        \draw[->] (ingest) -- node[left] (chunks) {add chunks} (DB);
        \draw[->] (DB) -- node[above] {top chunks} (retrieve);
        \draw[->] (retrieve) -- node[left, align=center] {save\\context} (workspace);
        \draw[->, transform canvas={yshift=1mm}]
        (workspace) -- node[above, align=center] {get context} (answer);
        \draw[->, transform canvas={yshift=-1mm}]
        (answer) -- node[below, align=center] {save answer} (workspace);
        \draw[->, transform canvas={xshift=1mm}]
        (answer) -- node[right, align=center] {prompt\\with context} (LLM);
        \draw[->, transform canvas={xshift=-1mm}]
        (LLM) -- node[left] {answer} (answer);
    \end{tikzpicture}
    % TODO: revisit colors
    \caption{The \gls{rag} agent manipulates the \textcolor{red}{workspace} folder with \textcolor{blue}{abilities}.
        To ingest a PDF, the user has to place the file into the workspace.
        After chunking the PDF, the chunks are ingested into the vector database.
        With the retrieval ability,
        the agent can retrieve the top five chunks for a query
        and save them in a workspace file.
        The retrieved documents are read from the workspace by the Answer ability.
        The generated answer is then written back into a file in the workspace.}
    \label{fig:abilities_workspace}
\end{figure}

Encoding knowledge in natural language is an everyday process for humans,
but has been a problem for machines for decades.

In recent years, there has been a large increase in language modeling capabilities.
After the proposal of the transformer architecture \cite{Vaswani2017},
which removed all sequential components from previous language modeling techniques,
the architecture and its components were applied to all kinds of language modeling problems.
Using \glspl{llm}, researchers were able to
see emerging behaviors, meaning that the model can solve tasks that it was not trained on.

Humans need to retrieve information from somewhere constantly.
It can be a task like digging out an old and hidden memory
or finding a book that contains the desired information.
Improving the efficiency of tasks like the latter
has been extensively researched in the \gls{ir} area in the last decades.
With the introduction of Internet search engines and data repositories,
the barrier to accessing information has been drastically improved.

This thesis presents a \gls{llm} agent that uses \gls{rag} to answer user prompts.
The creation of benchmarks for \gls{llm} agents is a complex endeavor.
Therefore, I will use a simple question-and-answer dataset
to benchmark the agent's performance with subjective evaluation.

\section{Contributions of this Thesis}

Three main contributions of this Thesis are

\begin{enumerate}
    \item An analysis of \gls{autogpt} and its default agent for \gls{ir} tasks.
    \item An \gls{ir} agent that uses \gls{rag}.
    \item A way to benchmark an \gls{ir} agent using the \gls{autogpt} benchmarking system with a synthetic \gls{ir} dataset.
\end{enumerate}

\section{Related Work}

With the rise of \glspl{llm}, they have been introduced into different domains.
\Gls{llm} agents are a promising way to fulfill user goals autonomously,
hinting in the direction of real computer intelligence.
Language models have also seen rising popularity in \gls{ir} applications.
Many popular search engines have introduced language models to present the retrieved data to the user.
In the following, notable work that is of interest for this work is listed.

\subsection{\gls{llm} Agents}

After \glspl{llm} like \gls{gpt3} and then \gls{gpt4} were made public,
researchers started testing different approaches to integrate them into agents.
In particular, the introduction of tools to extend the language model capabilities
Toolformer \cite{Schick2023} trains a language model to use different APIs in a self-supervised way.
For example, the model can use a calculator to externalize math problems,
a task category that \glspl{llm} struggle with.
HuggingGPT \cite{Shen2023} uses \gls{gpt} repeatedly in multiple rounds.
For each step, a Huggingface model can be selected by the model to answer the prompt.
In a virtual social setting, multiagent communication was demonstrated in \autocite{Park2023}.
Agents living together in a virtual village have different goals and communicate through natural language.

Building on top of these research experiments with tool usage and access to external knowledge,
multiple applications of language model agents have been presented.
\gls{autogpt} \cite{SignificantGravitas2024} is an attempt to make \gls{llm} autonomous,
but other projects have since been published.
An introduction to \gls{autogpt} is given in \autoref{ch:autogpt}.
BabyAGI is a minimal task-driven autonomous agent \cite{Nakajima2024}.
With the OpenAI assistants API,
users can build custom assistants
that can use OpenAI models, tools and knowledge to answer user queries \cite{zotero-195}.


\subsection{\gls{llm} Information Retrieval}

Because of their strong natural language capabilities,
many developers work on tools that use these models for \gls{ir}

In a variety of application contexts,
the answers of an assistant have to be correct.
This is especially true in research contexts.
A model that hallucinates is not feasible in this case. %TODO: was ist hallucination
But while hallucination can be reduced with fine-tuning,
it can not be eliminated.

Perplexity AI \cite{zotero-197} is an online service that leverages a language model
to provide a search that generates an answer from different sources on the internet.
The content of the answer is then linked to the found sources,
so the user can see and verify the result.
As this is a proprietary closed-source product accessible through a web interface,
this is not useful to create our custom research assistant.
The provided API simply hosts different language models and allows prompting them.
There is no possibility of fine-tuning.

\section{Structure of this Thesis}

First, I will introduce the main \emph{backgrounds}
that are relevant to this work in \autoref{ch:backgrounds}.
The steps of an \gls{ir} system are explained, as well
as different strategies to evaluate such systems.
Furthermore, I will give an overview of the concept of an \emph{agent} and its main components.
Additionally, the \emph{language modeling} section covers the base
to understand the current \glspl{llm}.
I will go from the introduction of the transformer architecture to current chat models like ChatGPT.
Finally, the combination of language models and agents to \emph{\gls{llm} agents} is introduced.

Chapter~\ref{ch:autogpt} contains an \emph{introduction to \gls{autogpt}} and its core elements,
as well as an analysis of its current \gls{ir} capabilities.
First, an overview of the \gls{autogpt} project and its components is given.
I will then explain the default agent in more detail,
looking at how the \gls{llm} agent ideas are implemented.
After gaining an understanding of the \gls{autogpt} project,
we will then look at its default capabilities for \gls{ir} tasks.

In \autoref{ch:agent},
a custom \gls{autogpt} agent that uses \gls{rag} for \gls{ir} is presented.
In \autoref{ch:benchmarks}, will deal with how \gls{llm} agents can be benchmarking
and present a test dataset for the \gls{rag} agent from \autoref{ch:agent}.
The benchmark uses handcrafted question-and-answer pairs from a scientific humanities journal.

Finally, a conclusion is given in \autoref{ch:conclusion}.
Here I will describe the problems and challenges
that \gls{llm} agents currently have being a relatively new concept.
Additionally, open questions for possible future work are discussed.

\end{document}