\documentclass[../main.tex]{subfiles}

\begin{document}
\chapter{An Analysis of AutoGPT}
\label{ch:autogpt}

% FIXME: this introduction consists of snippets that were copy and pasted together
% TODO: revise introduction
The general notion of an agent in computer science was introduced in \autoref{sec:agents}.
\gls{autogpt} is an open-source project that tries to 'make \gls{gpt} fully autonomous'.
The project quickly gained a lot of traction
following its first release.
The idea of an LLM that controls an agent sounded like the next step towards
real intelligence of computer systems.
Lots of programmers joined the \gls{autogpt} Repository,
and it grew into a much bigger and now-funded project.
Initially, it only contained the \gls{autogpt} agent
but over time has seen multiple additions.

The documentation of \gls{autogpt} is sparse,
and the project is developed quickly,
therefore existing documentation
can often be outdated.
Therefore, I will give a brief introduction to \gls{autogpt} and its core components
in this chapter.

What grabbed the attention of many people is not the whole project,
but merely the default agent of \gls{autogpt}.
The project further includes \emph{Forge},
an agent framework that can be used to build a custom agent.
It defines a minimal agent without logic
that abstracts away all the boilerplate.
In \autoref{subsec:forge_agent} the Forge agent is introduced
and in \autoref{ch:agent} I use the Forge agent
to build a custom agent for \gls{ir}.
While the first iteration of the default agent lived in the terminal,
the project now ships with a web application
that allows interaction with agents in the browser.
Finally, a benchmarking system was introduced.
The benchmarking can be used to build level-based test suites,
to test the capabilities of an agent.
The benchmarking system is introduced in \autoref{subsec:benchmarking}.

In the final section~\ref{sec:analysis} the project and its components
are analyzed in the context of information retrieval.

Originally,
the default only ran in the computer terminal
and was controlled through the command line.
Later, an option to start a server that implements the agent protocol was added.
The user can interact with the agent through a web interface in the browser.

The web interface lists all conversations an agent had and provides a chat interface for the selected one.
When the user sends an input to the agent, a task or step request is made to the server running the agent.
Furthermore, the web interface can be used to start benchmarks for an agent.
A single test or a complete test suite consisting of stages can be started.
The GUI has no support for uploading documents to an agent.
Because of this, documents for \gls{ir} would need to be placed in specific folder locations
such that the agent can access them before it is started.

\gls{autogpt} agents use workspaces in which they can act.
Each agent has its workspace and can not modify files outside it by default.
In case the user wants the agent to have access to documents, he needs to place them into its workspace by hand.
Often, the workspace is also used to save intermediate information to text files.
Some abilities produce large outputs,
and the limited context window of large language models can be exceeded quickly
if all intermediate information is appended to the prompt.

\section{Main Components}
\label{sec:default_agent}

\subsection{Default Agent}

The default agent made up the whole project when \gls{autogpt} was first released.
The official documentation \autocite{zotero-189} describes the default agent as:
\begin{quote}
      ``A \emph{generalist} agent, meaning it is not designed with a specific task in mind.
      Instead, it is designed to be able to execute a wide range of tasks across many disciplines,
      as long as it can be done on a computer.''
\end{quote}

The \gls{autogpt} agent is modeled after the classic agent architecture.
After the start,
the user is asked to enter a task the \gls{autogpt} agent should perform.
Then the agent enters a loop of prompting the LLM,
executing the proposed action
handling the result of the action and updating the agent state.

The LLM is prompted in a structured way.
A base prompt template is defined
and populated with current information before each prompting step.
The information includes the task at hand,
a list of possible actions,
a history of previous actions and their results
and some extra statements that are there to guide the language model.
As the answer needs to be parsed,
the system prompt defines a fixed format the LLM should answer in.
The answer consists of the thoughts and the proposed next action.

\gls{autogpt} is divided into four modules.
The \emph{brain} is the main module that controls the agent.
In \gls{autogpt} this is realized by prompting the language model in a structured way.
Using the chat system prompt,
the language model is prompted to answer in a structured format.
Different techniques are implemented in this structure.
The language model is forced not only to plan the next step
but also to explain the choice for the chosen step and to add self-criticism.
An extra output for the human user is also returned.
The second part of the answer is the actual next action with the needed arguments.
The action makes up the second module of the agent.
In this module, the abilities of the agent are defined.
These can be file operations,
database queries or web search functionalities.

The third module is the \emph{memory}.
Memories are modeled after humans which have short and long-term memory.

Currently,
the \gls{autogpt} agent is implemented for OpenAI \gls{gpt} models.
The prompts are tailored in ways
that benefit the characteristics of GPT-3 and GPT-4.
This generalist design can be seen in the list of available abilities.
\begin{description}
      \item[Code Execution] The agent can execute arbitrary Python code given as a
            string or a file.
            The execution is contained in a docker container
            that can access the agent workspace.
      \item[File Operations] To access files in the agent workspace,
            it has abilities to list, read and write files.
      \item[Image Generation]
            The agent can make calls to different image-generation services
            that transform a prompt into an image.
      \item[Web Search]
            Web search is the most common application of the default agent.
            The agent has abilities to query a search engine
            and scrape website content using a headless browser.
      \item[Other]
            Further abilities are present in the default agent.
            The user can be prompted to give more information about the task,
            the system time can be retrieved, and a completion ability is implemented.
\end{description}
Since the development of the default agent started,
different abilities have been present and were then removed again.
For example, efforts were made to introduce long-term memory to the agent.
There were abilities to save agent conversations into a database for later retrieval.
The idea was to improve the agent's performance by using past conversations as context.
However, experiments showed that using past conversations rather hindered its capabilities. % TODO: source
This is only an example of the constant development and changing constraints
one has to deal with when working with the default agent.

\subsection{Forge Agent}
\label{subsec:forge_agent}

To make collaboration with agents easier, the open-source community created the agent protocol.
The Agent Protocol defines an API schema that handles the communication with an agent.
On a high level, the protocol defines endpoints to create a task and to trigger the next step for the task.
The two important concepts of the agent protocol are tasks and steps:

\begin{description}
      \item[Task] A task describes a goal for the agent.
            A task has an input prompt and contains a list of steps.
      \item[Step] A step describes a single action of the agent.
            A step can have custom input or copy the task input.
            Additionally, there is a variable that signals if this is the last step.
            If this variable is false, then the next step is requested automatically after completing the current.
            Every step has to be linked to a parent task.
\end{description}

The Forge SDK handles the boilerplate code that implements the agent protocol.
On running, the server with the corresponding endpoints gets started, and the agent can be used over the API endpoints.
\gls{autogpt} also comes with a chatbot web app that builds the appropriate HTTP requests to the agent endpoints.
The user of the Forge SDK has to create the actual agent logic, create custom prompt templates for the used model and add abilities to interact with external resources.
Because the Forge SDK is still under development and by no means a polished product, some internals also need to be tweaked to achieve the desired agent behavior.

By default, the Forge agent comes with abilities to read and write text files and to search a search engine as well as scraping a webpage.
Each ability is specific by a name that the LLM can use to call it.
Additionally, a short description of what the ability does, input parameters and return types are described.
The information about an ability is formatted into a string before adding it to the step prompt.

\begin{description}
      \item[File System] The file system abilities allow operations on files located in the workspace of the agent.
            The agent can only operate in the defined workspace, this prevents unwanted effects when the agent proposes unexpected actions.
            Abilities to read, write and list files are present.
            All the abilities have a path parameter that the large language model has to populate when generating a step proposal with actions from this category.
      \item[Web] The web search functionality is split up into abilities to call a search engine and to read a webpage
            The web-search ability requires a search string that is sent to the engine.
            For the webpage ability a URL is needed, and if specific information should be extracted the LLM also has to provide a question.
      \item[Finish] The “finish” ability terminates the agent loop.
            The agent is asked to choose this ability if the initial user prompt can be answered and give a reason.
\end{description}

The Forge agent comes with a built-in template engine that is used
to populate the prompts before sending them to the large language model.
Some templates are included by default:

\begin{description}
      \item[Task-Step] This template is used to create the prompt that is sent to the language model for each step.
            It includes the current task description and placeholders for extra information.
            The template always needs to be populated with the list of available abilities,
            allowing the language model to choose one of them.
      \item[System-Format] The system format defines how the model should respond to prompts.
            The Forge system format is depicted in \autoref{lst:system-format}.
            The responses of the model need to be parsed according to this definition.
            Language models have different capabilities in answering in a structured manner, % TODO: source for structured generation
            so the format has to be tuned for every model.
      \item[Techniques] Techniques is a collection of prompting techniques that have been shown to improve generation quality.
            By default, the Forge agent has templates for few-shot, expert and chain-of-thought prompting. % TODO: explain in backgrounds
\end{description}

\begin{Code}[
            caption={The system format of the Forge agent.
                        The language model is asked to only answer in this format.
                        The thoughts before creating the output for the user (speak),
                        the LLM generates reasoning, a plan and criticism.
                        After the model generated its thoughts,
                        it generates an ability proposal with the corresponding arguments.},
            label={lst:system-format},
            captionpos=b,
            float=tp]
      Reply only in JSON with the following format:

      {
      \"thoughts\": {
      \"text\":  \"thoughts\",
      \"reasoning\": \"reasoning behind thoughts\",
      \"plan\": \"- short bulleted\
      - list that conveys\
      - long-term plan\",
      \"criticism\": \"constructive self-criticism\",
      \"speak\": \"thoughts summary to say to user\",
      },
      \"ability\": {
      \"name\": \"ability name\",
      \"args\": {
      \"arg1\": \"value1", etc...
      }
      }
      }
\end{Code}

The core of an agent is its logic.
The Forge agent comes without any logic,
its default behavior is to write a boilerplate text into a file in the workspace.

\subsection{Benchmarking System}
\label{subsec:benchmarking}

To evaluate \gls{autogpt} and other agent systems that implement the agent protocol,
the \gls{autogpt} project has implemented a benchmarking system.
The system consists of a set of tasks that the agent has to complete.
The tasks are designed to test different aspects of the agent and are divided into different topics.
Some tasks depend on the previous successful completion of other tasks.
A task consists of an input prompt and an expected output.
The output is defined by certain words that should be contained.

\section{Analysis for Information Retrieval}
\label{sec:analysis}

% FIXME revise analysis of autogpt, look at notes in thunderbird

AutoGPT was not built with information retrieval as a primary objective in mind.

The \gls{autogpt} Agent has different abilities that can be utilized for \gls{ir}.
It can search the web and operate on files, execute code and do other stuff.

The web search is implemented by a two-step process.
First, a search API like DuckDuckGo is called to get a list of relevant pages.
Then the page contents are scraped with a headless browser.
It is possible to read and write text files.
Other document types are processed by basic text extraction tools to get the plain text.

For longer files such as scientific journals the extracted text is too long for the language model.
The \gls{autogpt} agent cannot chunk the text into smaller chunks or store it in a database.
This is a limitation that needs to be addressed for \gls{ir} tasks over a local database repository.

Having a vector database would enable techniques such as \gls{rag}.
The agent would get a prompt with a question over the RDR and choose an action to start a semantic search over the vector database.
The result of the search is the chunks that are semantically closest to the question.
These chunks can then be included as context for the \gls{llm} prompt to generate an answer.

The default agent tends to search the web for information.
We want an agent that prioritizes information that is present in the research repository.
This needs to be addressed in the prompting techniques of the agent.


\end{document}
