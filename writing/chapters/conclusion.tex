\documentclass[../main.tex]{subfiles}

\begin{document}

Using language model agents for information retrieval tasks is an interesting approach,
but needs to overcome some key challenges for usage in real-world applications.

\section{Future Work}

The research area about large language models currently moves at a rapid pace.
While writing this thesis, communities have focused more on agent applications of LLMs.
OpenAI has released OpenAI Assistants, which\dots.
The AutoGPT team is still working on making the use of local models feasible.
In this work, only information retrieval over local documents was done.
This could be extended with web searching capabilities to include external information on demand.
For retrieval augmented generation, the ingestion of documents into the vector database is a crucial step.
The popular chunking methods for unstructured data like PDFs simply split the text to get a certain chunk size.
Methods for semantically splitting up unstructured data might improve the performance of retrieval augmentation pipelines.


\end{document}