\documentclass[../main.tex]{subfiles}

\begin{document}
\chapter{Conclusion}
\label{ch:conclusion}

Using language model agents for \gls{ir} tasks is an interesting approach,
but needs to overcome some key challenges for usage in real-world applications.

\section{Future Work}

The research area about large language models currently moves at a rapid pace.
While writing this thesis, communities have focused more on agent applications of \glspl{llm}.
OpenAI has released OpenAI Assistants, which\dots.
The \gls{autogpt} team is still working on making the use of local models feasible.
In this work, only \gls{ir} over local documents was done.
This could be extended with web searching capabilities to include external information on demand.
For \gls{rag}, the ingestion of documents into the vector database is a crucial step.
The popular chunking methods for unstructured data like PDFs simply split the text to get a certain chunk size.
Methods for semantically splitting up unstructured data might improve the performance of retrieval augmentation pipelines.


\end{document}