@InProceedings{Schiff2023,
  author    = {Schiff, Simon and Möller, Ralf},
  booktitle = {Proceedings of the Workshop on Humanities-Centred Artificial Intelligence (CHAI 2023)},
  title     = {Persistent Data, Sustainable Information},
  pages     = {5--14},
  publisher = {CEUR Workshop Proceedings},
  url       = {https://ceur-ws.org/Vol-3580/paper1.pdf},
  abstract  = {In almost all academic fields, results are derived from found evidence such as digitized objects stored at a repository. Deriving results from such repositories can be time and cost intensive, as data is often difficult to reuse. Guidelines such as FAIR (Findability, Accessibility, Interoperable, and Reuse) are intended to disseminate the proper archiving of research data such that, among others, archived data is easy to reuse. However, we argue that even if one follows FAIR guidelines, it is still challenging to derive results by reusing data. First of all, before reusing data from any repository, one needs to find the data. Search engines can index data stored at repositories, as data is associated with metadata as proposed by the FAIR guidelines. Deciding whether the data found is relevant usually requires downloading, extracting and visualizing the entire dataset which is time-consuming and costly. We propose that data need to be archived by associating it with metadata that determines how data can be prepared to support decision making. Metadata links data with executable code that can create an information system from associated data on demand. With our solution, data is easier to reuse, as one can decide whether found data is relevant. In addition, if the data is found to be relevant, our information system allows researchers to clearly refer to specific regions in the data for data governance.},
  groups    = {Uni Lübeck},
  keywords  = {persistent data, sustainable information, research data, data management},
  month     = sep,
  rights    = {© 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
  year      = {2023},
}

@Misc{Wang2023,
  author        = {Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Ji-Rong},
  title         = {A Survey on Large Language Model based Autonomous Agents},
  doi           = {10.48550/ARXIV.2308.11432},
  eprint        = {2308.11432},
  abstract      = {Autonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at https://github.com/Paitesanshi/LLM-Agent-Survey.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution 4.0 International},
  keywords      = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences},
  month         = aug,
  primaryclass  = {cs.AI},
  publisher     = {arXiv},
  year          = {2023},
}

@Misc{Xi2023,
  author        = {Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and Zheng, Rui and Fan, Xiaoran and Wang, Xiao and Xiong, Limao and Zhou, Yuhao and Wang, Weiran and Jiang, Changhao and Zou, Yicheng and Liu, Xiangyang and Yin, Zhangyue and Dou, Shihan and Weng, Rongxiang and Cheng, Wensen and Zhang, Qi and Qin, Wenjuan and Zheng, Yongyan and Qiu, Xipeng and Huang, Xuanjing and Gui, Tao},
  title         = {The Rise and Potential of Large Language Model Based Agents: A Survey},
  doi           = {10.48550/ARXIV.2309.07864},
  eprint        = {2309.07864},
  abstract      = {For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many researchers have leveraged LLMs as the foundation to build AI agents and have achieved significant progress. In this paper, we perform a comprehensive survey on LLM-based agents. We start by tracing the concept of agents from its philosophical origins to its development in AI, and explain why LLMs are suitable foundations for agents. Building upon this, we present a general framework for LLM-based agents, comprising three main components: brain, perception, and action, and the framework can be tailored for different applications. Subsequently, we explore the extensive applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperation. Following this, we delve into agent societies, exploring the behavior and personality of LLM-based agents, the social phenomena that emerge from an agent society, and the insights they offer for human society. Finally, we discuss several key topics and open problems within the field. A repository for the related papers at https://github.com/WooooDyy/LLM-Agent-Paper-List.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  keywords      = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences},
  month         = sep,
  primaryclass  = {cs.AI},
  publisher     = {arXiv},
  year          = {2023},
}

@InProceedings{NEURIPS2022_b1efde53,
  author    = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Training language models to follow instructions with human feedback},
  editor    = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages     = {27730--27744},
  publisher = {Curran Associates, Inc.},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf},
  volume    = {35},
  year      = {2022},
}

@Misc{Radford2018,
  author     = {Alec Radford and Karthik Narasimhan and Tim Salimans and Ilya Sutskever},
  title      = {Improving Language Understanding by Generative Pre-Training},
  url        = {https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf},
  readstatus = {skimmed},
  year       = {2018},
}

@InProceedings{NIPS2017_3f5ee243,
  author         = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
  booktitle      = {Advances in Neural Information Processing Systems},
  title          = {Attention is All you Need},
  editor         = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  publisher      = {Curran Associates, Inc.},
  url            = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  volume         = {30},
  qualityassured = {qualityAssured},
  year           = {2017},
}

@Misc{devlin2019bert,
  author        = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  title         = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  eprint        = {1810.04805},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  year          = {2019},
}

@InProceedings{NEURIPS2022_9d560961,
  author    = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and ichter, brian and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  editor    = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages     = {24824--24837},
  publisher = {Curran Associates, Inc.},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf},
  volume    = {35},
  year      = {2022},
}

@InProceedings{Asselborn2023,
  author     = {Thomas Asselborn and Sylvia Melzer and Said Aljoumani and Magnus Bender and Florian Andreas Marwitz and Konrad Hirschler and Ralf M\"oller},
  booktitle  = {Proceedings of the Workshop on Humanities-Centred Artificial Intelligence (CHAI 2023)},
  title      = {Fine-tuning BERT Models on Demand for Information Systems Explained Using Training Data from Pre-modern Arabic},
  pages      = {38--51},
  publisher  = {CEUR Workshop Proceedings},
  url        = {https://ceur-ws.org/Vol-3580/paper5.pdf},
  abstract   = {Humanities scholars can use Large Language Models (LLMs) to simplify their work to analyse texts or recognise patterns in data. However, if a domain-specific problem needs to be solved, the existing models need to be fine-tuned. In the humanities, there is less training data available for fine-tuning, but there are increasing information systems with research data in that can be used for this purpose. To use data from information systems, humanities researchers need to be able to transform research data from information systems to training data so that it is suitable for training LLMs. However, assigning the correct labels (e.g., person, location, date) to the data can be challenging. This article describes how to fine-tune BERT models on demand for information systems explained using training data from pre-modern Arabic. The result we have achieved is that all archived research data can be used in a research data repository for fine-tuning models in short time and in a simplified way, i.e., without being an IT expert. Since the data was available in canonical form, it was possible to specify which fields could be assigned to which label by means of a manifest file. The results we obtained show that the fine-tuning process can be done in just a few minutes using a sample dataset and BERT. The Fine-tuning on Demand (FToD) process identified names of people, places, or dates that could not be recognised by the pre-trained model.},
  groups     = {Uni Lübeck},
  keywords   = {Fine-tuning on demand, BERT, pre-modern Arabic, manifest file Asselborn), 0000-0002-0144-5429 (S. Melzer), 0009-0004-8306-8621 (S. Aljoumani), 0000-0002-1854-225X (M. Bender), 0000-0002-9683-5250 (F. A. Marwitz), 0000-0002-6012-7711 (K. Hirschler), 0000-0002-1174-3323 (R. Möller)},
  month      = sep,
  priority   = {prio1},
  readstatus = {read},
  relevance  = {relevant},
  rights     = {© 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
  year       = {2023},
}

@InProceedings{Bender2023b,
  author    = {Magnus Bender and Tanya Braun and Ralf M\"oller and Marcel Gehrke},
  booktitle = {17th {IEEE} International Conference on Semantic Computing, ({ICSC} 2023), February 1-3},
  title     = {Unsupervised Estimation of Subjective Content Descriptions},
  doi       = {10.1109/icsc56153.2023.00052},
  publisher = {{IEEE}},
  url       = {https://dx.doi.org/10.1109/ICSC56153.2023.00052},
  groups    = {Uni Lübeck},
  keywords  = {Subjective Content Descriptions; Text Mining;Text Annotation;Sentence clustering},
  year      = {2023},
}

@InProceedings{Bender2023c,
  author    = {Magnus Bender and Kira Schwandt and Ralf M\"oller and Marcel Gehrke},
  booktitle = {Proceedings of the Workshop on Humanities-Centred Artificial Intelligence (CHAI 2023)},
  title     = {FrESH – Feedback-reliant Enhancement of Subjective Content Descriptions by Humans},
  pages     = {15--24},
  publisher = {CEUR Workshop Proceedings},
  url       = {https://ceur-ws.org/Vol-3580/paper3.pdf},
  groups    = {Uni Lübeck},
  month     = sep,
  year      = {2023},
}

@InProceedings{Bender2023,
  author    = {Magnus Bender and Tanya Braun and Ralf M\"oller and Marcel Gehrke},
  booktitle = {KI 2023: Advances in Artificial Intelligence},
  title     = {LESS is More: LEan Computing for Selective Summaries},
  doi       = {10.1007/978-3-031-42608-7_1},
  pages     = {1--14},
  publisher = {Springer Nature Switzerland},
  url       = {https://doi.org/10.1007/978-3-031-42608-7_1},
  groups    = {Uni Lübeck},
  journal   = {International Journal of Semantic Computing},
  year      = {2023},
}

@InProceedings{Kuhr2019,
  author    = {Felix Kuhr and Tanya Braun and Magnus Bender and Ralf M\"oller},
  booktitle = {Proceedings of {AI} 2019: Advances in Artificial Intelligence},
  title     = {{To Extend or not to Extend? Context-specific Corpus Enrichment}},
  doi       = {10.1007/978-3-030-35288-2_29},
  isbn      = {978-3-030-35288-2},
  pages     = {357--368},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  url       = {https://www.ifis.uni-luebeck.de/uploads/tx_wapublications/public_AI2019_paper_79.pdf},
  volume    = {11919},
  groups    = {Uni Lübeck},
  year      = {2019},
}

@Misc{Yang2023,
  author        = {Hui Yang and Sifu Yue and Yunzhong He},
  title         = {Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions},
  doi           = {10.48550/ARXIV.2306.02224},
  eprint        = {2306.02224},
  abstract      = {Auto-GPT is an autonomous agent that leverages recent advancements in adapting Large Language Models (LLMs) for decision-making tasks. While there has been a growing interest in Auto-GPT stypled agents, questions remain regarding the effectiveness and flexibility of Auto-GPT in solving real-world decision-making tasks. Its limited capability for real-world engagement and the absence of benchmarks contribute to these uncertainties. In this paper, we present a comprehensive benchmark study of Auto-GPT styled agents in decision-making tasks that simulate real-world scenarios. Our aim is to gain deeper insights into this problem and understand the adaptability of GPT-based agents. We compare the performance of popular LLMs such as GPT-4, GPT-3.5, Claude, and Vicuna in Auto-GPT styled decision-making tasks. Furthermore, we introduce the Additional Opinions algorithm, an easy and effective method that incorporates supervised/imitation-based learners into the Auto-GPT scheme. This approach enables lightweight supervised learning without requiring fine-tuning of the foundational LLMs. We demonstrate through careful baseline comparisons and ablation studies that the Additional Opinions algorithm significantly enhances performance in online decision-making benchmarks, including WebShop and ALFWorld.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution 4.0 International},
  keywords      = {Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  month         = jun,
  primaryclass  = {cs.AI},
  priority      = {prio1},
  publisher     = {arXiv},
  year          = {2023},
}

@InProceedings{Redzuan2023a,
  author    = {Nadja Redzuan and Marcel Gehrke and Ralf M\"oller and Tanya Braun},
  booktitle = {Proceedings of the Workshop on Humanities-Centred Artificial Intelligence (CHAI 2023)},
  title     = {On Domain-specific Topic Modelling Using the Case of a Humanities Journal},
  pages     = {25--37},
  publisher = {CEUR Workshop Proceedings},
  url       = {https://ceur-ws.org/Vol-3580/paper4.pdf},
  groups    = {Uni Lübeck},
  month     = sep,
  year      = {2023},
}

@InProceedings{Lewis2020,
  author    = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K\"{u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt\"{a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages     = {9459--9474},
  publisher = {Curran Associates, Inc.},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf},
  volume    = {33},
  year      = {2020},
}

@Misc{Schiff2020,
  author = {Simon Schiff},
  date   = {2020},
  title  = {AI-based Companion Services for Humanities},
}

 
@InProceedings{Park2023,
  author     = {Park, Joon Sung and O’Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
  booktitle  = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  date       = {2023-10},
  title      = {Generative Agents: Interactive Simulacra of Human Behavior},
  doi        = {10.1145/3586183.3606763},
  publisher  = {ACM},
  series     = {UIST ’23},
  collection = {UIST ’23},
}

@Comment{jabref-meta: databaseType:biblatex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Uni Lübeck\;0\;1\;0x334db3ff\;\;\;;
}
